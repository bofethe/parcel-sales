{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hillsborough County Parcel Comp Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder for some description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths for ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_path = '../data/raw/allsales_03_07_2025/allsales.dbf'\n",
    "parcel_path = '../data/raw/parcel_03_07_2025/parcel.dbf'\n",
    "sub_path = '../data/raw/parcel_03_07_2025/parcel_sub_names.dbf'\n",
    "dor_path = '../data/raw/parcel_03_07_2025/parcel_dor_names.dbf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parcel = gpd.read_file(parcel_path)\n",
    "df_sales = gpd.read_file(sales_path, encoding='ISO-8859-1')\n",
    "df_sub = gpd.read_file(sub_path)[['SUBCODE', 'SUBNAME']].drop_duplicates()\n",
    "df_dor = gpd.read_file(dor_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the data to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.to_parquet('../data/processed/allsales.parquet', engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DOR and SUB descriptive names to parcel data\n",
    "df_merge = df_parcel.merge(df_dor, left_on = 'DOR_C', right_on='DORCODE', how ='left').drop(columns = ['DOR_C'])\n",
    "df_merge = df_merge.merge(df_sub, left_on ='SUB', right_on='SUBCODE', how ='left').drop(columns = ['SUB'])\n",
    "\n",
    "df_parcel.to_parquet('../data/processed/parcel.parquet', engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_parquet('../data/processed/allsales.parquet')\n",
    "df_parcel = pd.read_parquet('../data/processed/parcel.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_sales, df_parcel, on='FOLIO', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
